{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyEEpBu_9pwr"
      },
      "source": [
        "!unzip /content/drive/MyDrive/dataset/archive.zip -d /content/drive/MyDrive/dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdTU6uP--bGQ"
      },
      "source": [
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "np.random.seed(11) # It's my lucky number\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import itertools\n",
        "\n",
        "import keras\n",
        "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras import backend as K\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras import backend as K "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8SYZOE8-ggf"
      },
      "source": [
        "folder_benign_train = '../content/drive/MyDrive/dataset/archive/data/train/benign'\n",
        "folder_malignant_train = '../content/drive/MyDrive/dataset/archive/data/train/malignant'\n",
        "\n",
        "folder_benign_test = '../content/drive/MyDrive/dataset/archive/test/benign'\n",
        "folder_malignant_test = '../content/drive/MyDrive/dataset/archive/test/malignant'\n",
        "\n",
        "read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "\n",
        "# Load in training pictures \n",
        "ims_benign = [read(os.path.join(folder_benign_train, filename)) for filename in os.listdir(folder_benign_train)]\n",
        "X_benign = np.array(ims_benign, dtype='uint8')\n",
        "ims_malignant = [read(os.path.join(folder_malignant_train, filename)) for filename in os.listdir(folder_malignant_train)]\n",
        "X_malignant = np.array(ims_malignant, dtype='uint8')\n",
        "\n",
        "# Load in testing pictures\n",
        "ims_benign = [read(os.path.join(folder_benign_test, filename)) for filename in os.listdir(folder_benign_test)]\n",
        "X_benign_test = np.array(ims_benign, dtype='uint8')\n",
        "ims_malignant = [read(os.path.join(folder_malignant_test, filename)) for filename in os.listdir(folder_malignant_test)]\n",
        "X_malignant_test = np.array(ims_malignant, dtype='uint8')\n",
        "\n",
        "# Create labels\n",
        "y_benign = np.zeros(X_benign.shape[0])\n",
        "y_malignant = np.ones(X_malignant.shape[0])\n",
        "\n",
        "y_benign_test = np.zeros(X_benign_test.shape[0])\n",
        "y_malignant_test = np.ones(X_malignant_test.shape[0])\n",
        "\n",
        "\n",
        "# Merge data \n",
        "X_train = np.concatenate((X_benign, X_malignant), axis = 0)\n",
        "y_train = np.concatenate((y_benign, y_malignant), axis = 0)\n",
        "\n",
        "X_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\n",
        "y_test = np.concatenate((y_benign_test, y_malignant_test), axis = 0)\n",
        "\n",
        "# Shuffle data\n",
        "s = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_train = X_train[s]\n",
        "y_train = y_train[s]\n",
        "\n",
        "s = np.arange(X_test.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_test = X_test[s]\n",
        "y_test = y_test[s]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFRM9hly-2HV"
      },
      "source": [
        "# Display first 15 images of moles, and how they are classified\n",
        "w=40\n",
        "h=30\n",
        "fig=plt.figure(figsize=(12, 8))\n",
        "columns = 5\n",
        "rows = 3\n",
        "\n",
        "for i in range(1, columns*rows +1):\n",
        "    ax = fig.add_subplot(rows, columns, i)\n",
        "    if y_train[i] == 0:\n",
        "        ax.title.set_text('Benign')\n",
        "    else:\n",
        "        ax.title.set_text('Malignant')\n",
        "    plt.imshow(X_train[i], interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muRhSf1U-5m5"
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes= 2)\n",
        "y_test = to_categorical(y_test, num_classes= 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rUaeOoL-8YP"
      },
      "source": [
        "# With data augmentation to prevent overfitting \n",
        "X_train = X_train/255.\n",
        "X_test = X_test/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbkxnHsw-_qW"
      },
      "source": [
        "# See learning curve and validation curve\n",
        "\n",
        "def build(input_shape= (224,224,3), lr = 1e-3, num_classes= 2,\n",
        "          init= 'normal', activ= 'relu', optim= 'adam'):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same',input_shape=input_shape,\n",
        "                     activation= activ, kernel_initializer='glorot_uniform'))\n",
        "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same', \n",
        "                     activation =activ, kernel_initializer = 'glorot_uniform'))\n",
        "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer=init))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    if optim == 'rmsprop':\n",
        "        optimizer = RMSprop(lr=lr)\n",
        "\n",
        "    else:\n",
        "        optimizer = Adam(lr=lr)\n",
        "\n",
        "    model.compile(optimizer = optimizer ,loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=5, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=1e-7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqNZnxEj_CgL"
      },
      "source": [
        "input_shape = (224,224,3)\n",
        "lr = 1e-5\n",
        "init = 'normal'\n",
        "activ = 'relu'\n",
        "optim = 'adam'\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "model = build(lr=lr, init= init, activ= activ, optim=optim, input_shape= input_shape)\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.2,\n",
        "                    epochs= epochs, batch_size= batch_size, verbose=0, \n",
        "                    callbacks=[learning_rate_reduction]\n",
        "                   )\n",
        "                   \n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DnSYPkA8omp"
      },
      "source": [
        "K.clear_session()\n",
        "del model\n",
        "del history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yi6cEty8rQH"
      },
      "source": [
        "# define 3-fold cross validation test harness\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=11)\n",
        "\n",
        "cvscores = []\n",
        "for train, test in kfold.split(X_train, y_train):\n",
        "  # create model\n",
        "    model = build(lr=lr, \n",
        "                  init= init, \n",
        "                  activ= activ, \n",
        "                  optim=optim, \n",
        "                  input_shape= input_shape)\n",
        "    \n",
        "    # Fit the model\n",
        "    model.fit(X_train[train], y_train[train], epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    # evaluate the model\n",
        "    scores = model.evaluate(X_train[test], y_train[test], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    K.clear_session()\n",
        "    del model\n",
        "    \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8o-rFgI9ve5"
      },
      "source": [
        "# Fitting model to all data\n",
        "model = build(lr=lr, \n",
        "              init= init, \n",
        "              activ= activ, \n",
        "              optim=optim, \n",
        "              input_shape= input_shape)\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=epochs, batch_size= batch_size, verbose=0,\n",
        "          callbacks=[learning_rate_reduction]\n",
        "         )\n",
        "\n",
        "# Testing model on test data to evaluate\n",
        "y_pred = model.predict_classes(X_test)\n",
        "\n",
        "print(accuracy_score(np.argmax(y_test, axis=1),y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtNdYwkH9yG2"
      },
      "source": [
        "# save model\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "# Clear memory, because of memory overload\n",
        "del model\n",
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DQ14kqb90tJ"
      },
      "source": [
        "input_shape = (224,224,3)\n",
        "lr = 1e-5\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "model = ResNet50(include_top=True,\n",
        "                 weights= None,\n",
        "                 input_tensor=None,\n",
        "                 input_shape=input_shape,\n",
        "                 pooling='avg',\n",
        "                 classes=2)\n",
        "\n",
        "model.compile(optimizer = Adam(lr) ,\n",
        "              loss = \"binary_crossentropy\", \n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.2,\n",
        "                    epochs= epochs, batch_size= batch_size, verbose=2, \n",
        "                    callbacks=[learning_rate_reduction]\n",
        "                   )\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whgZ9Mrv93Kl"
      },
      "source": [
        "# Train ResNet50 on all the data\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=epochs, batch_size= epochs, verbose=0,\n",
        "          callbacks=[learning_rate_reduction]\n",
        "         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RDeOjUI95gW"
      },
      "source": [
        "# Testing model on test data to evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))\n",
        "\n",
        "# save model\n",
        "# serialize model to JSON\n",
        "resnet50_json = model.to_json()\n",
        "\n",
        "with open(\"resnet50.json\", \"w\") as json_file:\n",
        "    json_file.write(resnet50_json)\n",
        "    \n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"resnet50.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}